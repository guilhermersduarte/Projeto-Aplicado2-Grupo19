{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b585923-1df0-4bb3-bd91-1e6a64063383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "token_count = 30000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0906e557-368f-4ad6-80a8-176ff4411e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Data                                              Texto  Selic  \\\n",
      "234 2025-05-07  a atualização da conjuntura econômica e do cen...  14.25   \n",
      "235 2025-06-18  a atualização da conjuntura econômica e do cen...  14.75   \n",
      "236 2025-07-30  a atualização da conjuntura econômica e do cen...  15.00   \n",
      "237 2025-09-17  a atualização da conjuntura econômica e do cen...  15.00   \n",
      "\n",
      "     IPCA  Selic (6m) Data (6m)  \n",
      "234  5.32         NaN       NaT  \n",
      "235  5.35         NaN       NaT  \n",
      "236  5.23         NaN       NaT  \n",
      "237  5.17         NaN       NaT  \n"
     ]
    }
   ],
   "source": [
    "input_data = pd.read_pickle('../dados/df_ata_sentimento_predict.pkl') \n",
    "#input_data = pd.read_json('../dados/df_ata_sentimento.json', orient='records', lines=True)\n",
    "#input_data['Data'] = pd.to_datetime(input_data['Data']).dt.date\n",
    "input_data['Texto'] = input_data['Texto'].str.lower()\n",
    "\n",
    "print(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d4a412d-67c2-4c9e-a492-8b7da752522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Recreate text_vec_layer if not saved\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# You must know the vocabulary or adapt it again from training data\n",
    "# If you saved the vocab, load it; otherwise, re-adapt on training data\n",
    "text_vec_layer = TextVectorization(\n",
    "    max_tokens=token_count,  # same as training\n",
    "    output_mode='int'\n",
    ")\n",
    "\n",
    "# Re-adapt if needed (only on training texts!)\n",
    "# text_vec_layer.adapt(train_texts)  # where train_texts is list of raw strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "909ba9a7-a516-443f-8107-8983d8ddc67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ricardo/Documents/Projeto2/Projeto-Aplicado2-Grupo19/Notebooks\n"
     ]
    }
   ],
   "source": [
    "# Load the best model saved via ModelCheckpoint\n",
    "print(os.getcwd())\n",
    "model = tf.keras.models.load_model('../../gru_sentimento_6m__GRU_0801_modl_sent_encoded_180_mzt_220_B32.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47359586-777e-445e-b2d7-8f43d079cbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[0 0 1 0 1 1 1 0 1 2 0 2 1 1 0 0 0 1 1 1 2 1 1 0 2 0 1 2 0 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(predicted_classes)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60fa3a5c-2005-4b48-9d83-d33239ee230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 13:07:02.481463: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at lookup_table_op.cc:932 : FAILED_PRECONDITION: Table not initialized.\n",
      "2025-10-20 13:07:02.481496: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: Table not initialized.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs=tf.Tensor(shape=(1,), dtype=string)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFailedPreconditionError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m new_text = \u001b[33m\"\u001b[39m\u001b[33mYour input string here\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Preprocess\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m input_vectorized = \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_vec_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mpreprocess_text\u001b[39m\u001b[34m(text, text_vec_layer)\u001b[39m\n\u001b[32m      3\u001b[39m text_tensor = tf.constant([text])\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Vectorize\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vectorized = \u001b[43mtext_vec_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vectorized\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tf2.20/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tf2.20/lib/python3.12/site-packages/keras/src/layers/preprocessing/index_lookup.py:766\u001b[39m, in \u001b[36mIndexLookup._lookup_dense\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    764\u001b[39m     lookups = tf.zeros_like(inputs, dtype=\u001b[38;5;28mself\u001b[39m._value_dtype)\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     lookups = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlookup_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mask_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    769\u001b[39m     mask_locations = tf.equal(inputs, \u001b[38;5;28mself\u001b[39m._mask_key)\n",
      "\u001b[31mFailedPreconditionError\u001b[39m: Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs=tf.Tensor(shape=(1,), dtype=string)"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text, text_vec_layer):\n",
    "    # Convert string to tensor\n",
    "    text_tensor = tf.constant([text])\n",
    "    # Vectorize\n",
    "    vectorized = text_vec_layer(text_tensor)\n",
    "    return vectorized\n",
    "\n",
    "# Example input\n",
    "new_text = \"Your input string here\"\n",
    "\n",
    "# Preprocess\n",
    "input_vectorized = preprocess_text(new_text, text_vec_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883d0ea-9a2a-437b-9ffb-4727b859409c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
